# 3

### Теория, лежащая в основе генетических алгоритмов (GAs)

Генетические алгоритмы (GAs) - это семейство вычислительных алгоритмов, основанных на принципах естественного отбора и генетики. Эти алгоритмы имитируют процесс эволюции, когда наиболее приспособленные особи отбираются для размножения, чтобы создать следующее поколение решений. GAs особенно полезны в задачах оптимизации и поиска, где они разрабатывают решения сложных задач с помощью механизмов, сходных с биологической эволюцией.

### Ключевые понятия в генетических алгоритмах

GAs основаны на нескольких ключевых концепциях, заимствованных из эволюционной биологии:

1. **Популяция**: Набор потенциальных решений, где каждая особь представляет точку в пространстве решений.
2. **Пригодность**: Показатель того, насколько хорошим является решение, часто определяется целевой функцией или функцией затрат.
3. **Отбор**: Процесс отбора особей на основе их пригодности для создания потомства для следующего поколения.
4. **Кроссинговер (рекомбинация)**: Объединение частей двух или более особей для создания нового потомства.
5. **Мутация**: Внесение случайных изменений в индивидуума для поддержания разнообразия в популяции и изучения новых пространств решений.

### Реализация генетического алгоритма

Предоставленный код генетического алгоритма представляет собой реализацию этих принципов, адаптированную для задач оптимизации:

1. **Инициализация**: Алгоритм запускается с начальной совокупности решений (`точек`), представляющих различных кандидатов.

2. ** Расчет пригодности **: Пригодность каждого человека рассчитывается на основе предоставленной функции. При оптимизации пригодность часто соответствует тому, насколько хорошо решение минимизирует или максимизирует целевую функцию.

3. **Отбор - Турнирный отбор**: Этот шаг включает отбор особей для воспроизводства. При отборе на турнир случайным образом выбирается подмножество населения и выбираются лучшие из них на основе физической подготовки. Этот процесс повторяется для выбора родителей.

4. **Кроссинговер - Равномерное скрещивание**: Потомство создается путем объединения признаков двух родителей. При равномерном скрещивании каждый ген (компонент решения) выбирается у любого из родителей с определенной вероятностью (`crossover_rate`), создавая смесь признаков обоих родителей.

5. **Мутация**: Чтобы внести вариабельность и избежать преждевременной конвергенции, потомство может подвергнуться мутации с определенной вероятностью (`mutation_rate`). Мутация включает изменение некоторых генов потомства, руководствуясь нормальным распределением (`mutation_scale`).

6. **Обновление поколения **: После создания нового поколения решений процесс оценки, отбора, скрещивания и мутации повторяется в течение указанного количества поколений (`num_generations`).

7. **Завершение и выходные данные **: Алгоритм завершает работу после заданного количества генераций. Наилучшее решение, найденное в ходе этих итераций, сообщается в качестве выходных данных, демонстрируя путь, пройденный алгоритмом для достижения этого решения.

В представленной реализации GA предназначен для решения задач минимизации, где пригодность обратно пропорциональна значению функции. Эффективность алгоритма в поиске оптимальных или близких к оптимальным решений проистекает из его способности сбалансировать исследование (поиск новых областей) и эксплуатацию (уточнение существующих решений) пространства поиска.

# 4

### Теория, лежащая в основе оптимизации роя частиц (PSO)

Оптимизация роя частиц (PSO) - это вычислительный метод, используемый для поиска оптимальных решений в различных типах задач. Он вдохновлен социальным поведением птиц и рыб. В PSO каждый индивид, называемый "частицей", представляет потенциальное решение в многомерном пространстве. Движение этих частиц определяется их собственным опытом и опытом их спутников, имитируя социальное поведение стай или косяков.

### Принципы PSO

Фундаментальные принципы PSO основаны на следующих концепциях:

1. ** Представление частиц**: Каждая частица в рое представляет потенциальное решение.
2. **Скорость **: Частицы перемещаются по пространству решений со скоростью, которая динамически регулируется в зависимости от их опыта и опыта их соседей.
3. ** Обновление положения **: Положение каждой частицы обновляется в зависимости от ее скорости, отражая поиск лучших решений.
4. ** Личный рекорд **: Каждая частица запоминает наилучшее положение, которое она когда-либо посещала, что определяет ее будущие перемещения.
5. **Глобальное наилучшее **: Наилучшее положение, найденное любой частицей в рое, влияет на движение всех частиц.

### Реализация алгоритма PSO

В представленном алгоритме PSO процесс поиска оптимального решения включает следующие шаги:

1. **Инициализация**: Рой частиц инициализируется со случайными положениями и скоростями. Количество частиц и их размерность определяются входными параметрами.

2. **Оценка **: Положение каждой частицы оценивается с использованием предоставленной целевой функции для определения качества раствора.

3. ** Обновите личные и глобальные рекорды **: Частицы обновляют свою личную лучшую позицию, если их новая позиция лучше. Лучшая из этих позиций считается лучшей в мире.

4. ** Обновление скорости **: Скорость каждой частицы обновляется на основе комбинации ее текущей скорости, расстояния от ее личного рекорда и расстояния от мирового рекорда. Это обновление включает случайные факторы для внесения разнообразия в поиск.

5. ** Обновление положения **: Частицы перемещаются в новые положения на основе их обновленных скоростей в поисках лучших решений.

6. **Итерация**: Этапы оценки, обновления и перемещения повторяются в течение заданного количества итераций, позволяя рою исследовать пространство решений.

7. **Завершение**: Алгоритм останавливается после заданного количества итераций. Сообщается о наилучшем решении, найденном в ходе этих итераций.

В данной реализации алгоритм PSO адаптируется к различным задачам оптимизации. Он использует такие параметры, как вес инерции, когнитивный коэффициент и социальный коэффициент, чтобы сбалансировать разведку и эксплуатацию в процессе поиска. Эффективность алгоритма заключается в его простоте и способности находить хорошие решения в сложных пространствах поиска.



# 5

### Теория, лежащая в основе оптимизации пчелиного роя

Оптимизация пчелиного роя (BSO), более известная как искусственная пчелиная колония (ABC), представляет собой алгоритм оптимизации, основанный на интеллектуальном поведении медоносных пчел при поиске пищи. Он был представлен компанией Karaboga в 2005 году для оптимизации численных задач. Алгоритм имитирует процесс поиска пчелами и использования источников пищи, что в контексте оптимизации соответствует нахождению оптимальных решений в пространстве поиска.

В природе медоносные пчелы делятся на три группы в зависимости от их ролей:

1. **Работающие пчелы**: Они связаны с конкретными источниками пищи, и их основная роль заключается в использовании этих источников. В BSO они представляют решения, которые совершенствуются итерация за итерацией.

2. **Пчелы-наблюдатели**: Они ждут в улье и выбирают источники пищи на основе информации, которой делятся работающие пчелы. Они представляют собой вероятностный выбор решений, основанный на пригодности, где лучшие решения имеют более высокие шансы быть отобранными для дальнейшего изучения.

3. ** Пчелы-разведчики **: Их отправляют на поиск новых источников пищи, когда исчерпываются существующие. В BSO они представляют собой случайный поиск новых решений, когда текущие решения не могут быть улучшены дальше, предотвращая застревание алгоритма в локальных оптимумах.

Алгоритм состоит из нескольких ключевых шагов:

- **Инициализация**: Совокупность решений (источников пищи) генерируется случайным образом.
  
- **Фаза занятой пчелы**: Каждая занятая пчела оценивает пригодность своего решения, а затем пытается найти лучшее решение (количество нектара) по соседству. В случае успеха пчела запоминает новое решение и забывает старое.

- ** Фаза пчел-наблюдателей **: После того, как все нанятые пчелы завершат поиск, они делятся информацией о нектаре с пчелами-наблюдателями. Затем наблюдатели вероятностно выбирают источники пищи (решения) для использования, отдавая предпочтение тем, у которых больше нектара (лучшая приспособленность).

- ** Фаза пчелы-разведчика **: Если источник пищи истощается (решение не может быть улучшено в дальнейшем в течение определенного количества испытаний), связанная с ним нанятая пчела становится разведчиком и случайным образом ищет новый источник пищи (новое случайное решение).

- **Отказ от решения и замена**: Если решение не может быть улучшено в пределах указанного предела (известного как "предел" в алгоритме), оно отменяется, и новое решение генерируется случайным образом для его замены.

### Реализация

Реализация BSO в Python соответствует приведенной выше теоретической базе:

1. **Инициализация**: Исходная совокупность генерируется на основе предоставленных баллов.

2. ** Оценка пригодности**: Рассчитывается пригодность каждого человека. Для задач минимизации пригодность часто принимается как величина, обратная значению функции.

3. **Фаза использования пчел **: Решения слегка видоизменяются, чтобы исследовать окрестности. Если новое решение лучше, оно сохраняется; в противном случае счетчик для этого решения увеличивается.

4. ** Фаза пчелы-наблюдателя **: Решения выбираются вероятностно на основе пригодности. Применяется тот же процесс мутации и отбора, что и в фазе занятой пчелы.

5. ** Фаза пчелы-разведчика **: Решения, которые не улучшились в течение ряда итераций, превышающих "лимит", заменяются новыми случайными решениями, имитирующими поведение пчелы-разведчика.

6. **Отказ от использования и замена**: Решения, которые не могут быть улучшены, заменяются, обеспечивая разнообразие в популяции и избегая локальных оптимумов.

7. **Генерация выходных данных**: Возвращаются пути (исторические наилучшие решения) и окончательное наилучшее решение. Эти выходные данные можно использовать для анализа или визуального представления производительности алгоритма.

Поддерживая баланс между локальной эксплуатацией и глобальными исследованиями, BSO может эффективно ориентироваться в пространстве поиска и часто находить хорошие решения сложных задач оптимизации.

# 6

### Теория, лежащая в основе искусственных иммунных систем (ИИ)

Искусственные иммунные системы (ИИ) - это класс биологически вдохновленных вычислительных алгоритмов, основанных на принципах и процессах иммунной системы позвоночных. Иммунная система - это надежная адаптивная система, которая учится распознавать патогены и бороться с ними. Алгоритмы ИИ черпают вдохновение из этой системы, в частности из механизмов распознавания, обучения и памяти. Одной из ключевых концепций ИИ является принцип клонального отбора, который объясняет, как иммунная система адаптируется к новым, неизвестным патогенам путем отбора и клонирования определенных типов иммунных клеток, которые могут распознавать и нейтрализовать эти угрозы.

### Принцип клонального отбора

Принцип клонального отбора лежит в основе нескольких алгоритмов AIS, включая алгоритм клонального отбора и алгоритм искусственной иммунной сети (AIN). Он включает в себя следующие этапы:

1. **Распознавание**: Обнаружение патогенов иммунными клетками (антителами).
2. **Селекция**: Отбор тех иммунных клеток, которые могут эффективно распознавать патогены.
3. **Клонирование**: Клонирование выбранных клеток.
4. **Мутация**: Введение мутаций в клонированные клетки для создания разнообразного набора клеток.
5. **Память**: Сохранение наиболее эффективных ячеек для более быстрого реагирования в будущем.

### Реализация алгоритма AIS

В контексте задач оптимизации алгоритм AIS можно рассматривать как метафору, где решения проблемы сродни антителам, а целевая функция представляет антиген. Целью алгоритма является разработка набора решений, которые наилучшим образом подходят для минимизации (или максимизации) целевой функции.

Вот как реализован алгоритм AIS, основанный на принципе клонального отбора:

1. **Инициализация**: Популяция растворов-кандидатов (антител) генерируется случайным образом в пространстве поиска.

2. **Расчет аффинности**: Аффинность (или пригодность) каждого решения-кандидата оценивается на основе целевой функции. При оптимизации более высокая аффинность соответствует лучшим решениям.

3. **Клональный отбор**: На основе их сродства отбираются решения-кандидаты для клонирования. Этот шаг способствует распространению решений более высокого качества.

4. **Гипермутация**: Клоны решений-кандидатов подвергаются процессу мутации, который вносит вариации. Частота мутаций обычно обратно пропорциональна аффинности — лучшие решения подвергаются меньшему количеству мутаций, чтобы сохранить свое качество, в то время как худшие решения подвергаются более радикальным изменениям в надежде найти лучшие.

5. **Отбор**: После мутации популяция подвергается переоценке, и для формирования нового поколения выбирается подмножество наиболее эффективных решений.

6. **Введение разнообразия **: Чтобы избежать преждевременной конвергенции к локальным оптимумам, некоторая степень разнообразия вводится путем случайной замены части совокупности новыми решениями-кандидатами.

7. **Итерация**: Процесс повторяется в течение нескольких поколений или до тех пор, пока не будет удовлетворен критерий сходимости.

В данной реализации алгоритм AIS специально разработан для решения задач минимизации. Он использует операцию сортировки для ранжирования мутировавших клонов на основе целевой функции и выбирает наилучший для формирования новой популяции. Кроме того, поддерживаются уникальные решения для четкой визуализации процесса конвергенции.

# 7

### Теория, лежащая в основе оптимизации поиска пищи бактериями (BFOA)

Алгоритм оптимизации поиска пищи бактериями (BFOA) - это вдохновленный природой вычислительный метод, основанный на поведении бактерий E. coli в процессе поиска пищи. Эти бактерии перемещаются по окружающей среде серией кувырков и плаваний в поисках питательных веществ, избегая при этом вредных веществ. Этот метод исследования и эксплуатации имитируется в BFOA для решения задач оптимизации.

### Ключевые концепции в BFOA

BFOA включает в себя несколько биологических концепций:

1. **Хемотаксис**: Этот процесс имитирует движение бактерий посредством кувыркания и плавания. Бактерии перемещаются в поисках питательных веществ (оптимальных растворов), корректируя свой путь в зависимости от местных градиентов в окружающей среде.

2. **Роение**: Бактерии, как правило, перемещаются группами, влияя на движения друг друга, хотя в некоторых реализациях BFOA этому аспекту уделяется меньше внимания.

3. **Размножение**: Более здоровые (приспособленные к жизни) бактерии размножаются активнее, передавая свои черты следующему поколению.

4. **Элиминация и расселение**: Случайные изменения в окружающей среде приводят к элиминации и расселению некоторых бактерий, привнося разнообразие.

### Реализация BFOA

Предоставленная реализация алгоритма BFOA следует этим шагам, адаптированным для оптимизации:

1. **Инициализация**: Инициализируется популяция бактерий (растворов). Положение каждой бактерии в многомерном пространстве представляет потенциальное решение.

2. **Хемотаксис**: Каждая бактерия совершает серию кувырков (случайных изменений направления) и последующих заплывов (перемещений в выбранном направлении). Продолжительность заплыва определяется тем, насколько полезным является перемещение, оцениваемое с использованием целевой функции.

3. **Оценка здоровья**: Здоровье каждой бактерии оценивается на основе целевой функции. Более низкие значения функции указывают на лучшее здоровье.

4. **Размножение**: Бактерии сортируются по их здоровью, и более здоровая половина размножается, в то время как менее здоровая половина уничтожается. Численность населения остается постоянной.

5. **Элиминация и расселение**: С определенной вероятностью некоторые бактерии случайным образом уничтожаются, а новые бактерии вводятся в случайных местах. Этот процесс помогает поддерживать генетическое разнообразие и предотвращает преждевременную конвергенцию.

6. **Итерация**: Эти шаги повторяются в течение заданного количества итераций. На протяжении этих итераций бактерии исследуют пространство решений, продвигаясь к более оптимальным решениям.

7. **Завершение и вывод**: Алгоритм завершает работу после заданного количества итераций. Наилучшее положение и значение, найденные во время этих итераций, сообщаются в качестве выходных данных.

В этой реализации BFOA адаптирован для задач минимизации. Алгоритм эффективно уравновешивает разведку (поиск новых областей пространства поиска) и эксплуатацию (уточнение существующих решений), что делает его пригодным для решения сложных задач оптимизации.

# 8

### Теория, лежащая в основе гибридной оптимизации PSO-GA

Гибридная оптимизация роя частиц (PSO) и генетический алгоритм (GA) сочетают в себе сильные стороны как PSO, так и GA для эффективного решения задач оптимизации. PSO - это технология, основанная на роевом интеллекте, вдохновленная социальным поведением птиц и рыб, эффективная при изучении пространства решений. GA, вдохновленная принципами естественного отбора и генетики, превосходно использует пространство поиска с помощью таких механизмов, как скрещивание и мутация.

### Ключевые концепции гибридного PSO-GA

Этот гибридный подход использует:

1. ** Исследование с помощью PSO**: Первоначально PSO используется для изучения пространства поиска. Частицы (потенциальные решения) перемещаются в соответствии со своим собственным опытом и опытом роя, что приводит к широкому исследованию пространства решений.

2. **Эксплуатация с помощью GA **: GA занимает конечные позиции на этапе PSO и использует эволюционные принципы для использования пространства поиска. Посредством отбора, скрещивания и мутации GA совершенствует решения, комбинируя и изменяя характеристики существующих решений.

### Реализация гибридного алгоритма PSO-GA

Предоставленная реализация выполняется следующим образом:

1. **Фаза PSO**:
   - **Инициализация**: Алгоритм начинается с набора начальных точек, представляющих потенциальные решения.
   - **Итерации PSO**: Для определенного числа итераций применяется алгоритм PSO. Частицы корректируют свое положение на основе личных и глобальных рекордов, используя такие параметры, как инерционный вес (w), когнитивный (c1) и социальный коэффициенты (c2).
   - **Результат**: Конечные положения частиц после фазы PSO используются в качестве входных данных для фазы GA.

2. **Фаза GA**:
   - **Инициализация с результатами PSO**: GA начинается с конечных позиций, полученных на этапе PSO.
   - **Итерации GA**: GA работает в течение заданного количества поколений. Он включает в себя селекцию (выбор наиболее подходящих решений), скрещивание (объединение признаков родительских решений для создания нового потомства) и мутацию (внесение вариаций для поддержания разнообразия).
   - **Параметры**: Частота и масштаб мутаций определяют вероятность и степень изменений в процессе мутации.
   - **Результат**: Фаза GA дополнительно уточняет решения, фокусируясь на использовании перспективных областей, определенных PSO.

3. **Завершение и выходные данные**:
   - Алгоритм завершается после завершения как этапов PSO, так и GA.
   - Сообщается о наилучшем положении и значении, найденных на этих этапах.

Этот гибридный подход разработан для оптимизации баланса между разведкой и эксплуатацией. Фаза PSO быстро исследует пространство решений для выявления перспективных регионов, в то время как фаза GA использует эти регионы для уточнения решений. Такая комбинация часто приводит к повышению производительности в сложных задачах оптимизации по сравнению с использованием только PSO или GA.